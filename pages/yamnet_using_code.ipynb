{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "bbQwjpzzCz_V",
        "outputId": "8ddfa2d1-c4d5-41cf-af7e-dd53ea9ff561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Loading YAMNet model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Loading drone classifier model...\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# üß© Imports\n",
        "# ============================\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "from tkinter import Tk, filedialog\n",
        "\n",
        "# ============================\n",
        "# ‚öôÔ∏è Configuration\n",
        "# ============================\n",
        "DEFAULT_SR = 16000  # Default sampling rate (you can change this)\n",
        "WINDOW_SEC = 1.0\n",
        "HOP_SEC = 0.5\n",
        "\n",
        "# ============================\n",
        "# üß† Load pretrained models\n",
        "# ============================\n",
        "print(\"üîπ Loading YAMNet model...\")\n",
        "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
        "\n",
        "print(\"üîπ Loading drone classifier model...\")\n",
        "drone_model = tf.keras.models.load_model(\"yamnet_drone_classifier.h5\")  # make sure this file is in the same folder\n",
        "\n",
        "# ============================\n",
        "# üéß Load full audio file\n",
        "# ============================\n",
        "def load_full_audio(file_path, sr=DEFAULT_SR):\n",
        "    \"\"\"\n",
        "    Load an audio file and resample to the given sampling rate.\n",
        "    \"\"\"\n",
        "    audio, _ = librosa.load(file_path, sr=sr, mono=True)\n",
        "    return audio\n",
        "\n",
        "# ============================\n",
        "# ü™ü Split audio into windows\n",
        "# ============================\n",
        "def sliding_window(audio, sr=DEFAULT_SR, window_sec=WINDOW_SEC, hop_sec=HOP_SEC):\n",
        "    \"\"\"\n",
        "    Split audio into overlapping windows.\n",
        "    \"\"\"\n",
        "    window_size = int(window_sec * sr)\n",
        "    hop_size = int(hop_sec * sr)\n",
        "    windows = []\n",
        "    for start in range(0, len(audio) - window_size + 1, hop_size):\n",
        "        segment = audio[start:start + window_size]\n",
        "        windows.append(segment)\n",
        "    # Handle short files\n",
        "    if not windows:\n",
        "        pad = np.pad(audio, (0, max(0, window_size - len(audio))))\n",
        "        windows.append(pad)\n",
        "    return np.array(windows)\n",
        "\n",
        "# ============================\n",
        "# üîç Analyze full audio\n",
        "# ============================\n",
        "def analyze_audio(file_path, sr=DEFAULT_SR, window_sec=WINDOW_SEC, hop_sec=HOP_SEC):\n",
        "    \"\"\"\n",
        "    Analyze an audio file and detect drone presence over time.\n",
        "    \"\"\"\n",
        "    audio = load_full_audio(file_path, sr=sr)\n",
        "    windows = sliding_window(audio, sr=sr, window_sec=window_sec, hop_sec=hop_sec)\n",
        "    times = np.arange(len(windows)) * hop_sec\n",
        "\n",
        "    preds = []\n",
        "    print(f\"\\nüîç Analyzing {len(windows)} audio segments...\")\n",
        "    for segment in tqdm(windows, desc=\"Processing\"):\n",
        "        segment_tensor = tf.convert_to_tensor(segment, dtype=tf.float32)\n",
        "        # Extract embeddings using YAMNet\n",
        "        scores, embeddings, spectrogram = yamnet_model(segment_tensor)\n",
        "        mean_embedding = tf.reduce_mean(embeddings, axis=0, keepdims=True)\n",
        "        # Predict with trained model\n",
        "        pred = drone_model.predict(mean_embedding, verbose=0)\n",
        "        preds.append(pred[0])\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    return times, preds\n",
        "\n",
        "# ============================\n",
        "# üìä Plot detection results\n",
        "# ============================\n",
        "def plot_detection(times, preds, threshold=0.5):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(times, preds[:, 0], label=\"Drone Probability\", color=\"red\")\n",
        "    plt.axhline(threshold, color='gray', linestyle='--', label='Threshold')\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(\"Drone Detection Timeline\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# ============================\n",
        "# üß™ Main Execution\n",
        "# ============================\n",
        "if __name__ == \"__main__\":\n",
        "    # Choose audio file interactively\n",
        "    root = Tk()\n",
        "    root.withdraw()  # Hide tkinter window\n",
        "    file_path = filedialog.askopenfilename(\n",
        "        title=\"Select an audio file\",\n",
        "        filetypes=[(\"Audio Files\", \"*.wav *.mp3 *.flac *.ogg\")]\n",
        "    )\n",
        "    \n",
        "    if not file_path:\n",
        "        print(\"‚ùå No file selected.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\n‚úÖ Selected file: {file_path}\")\n",
        "\n",
        "    # Choose sampling rate\n",
        "    try:\n",
        "        sr = int(input(f\"Enter sampling rate (default = {DEFAULT_SR}): \") or DEFAULT_SR)\n",
        "    except ValueError:\n",
        "        sr = DEFAULT_SR\n",
        "\n",
        "    print(f\"üéö Using sampling rate: {sr} Hz\")\n",
        "\n",
        "    # Run analysis\n",
        "    times, preds = analyze_audio(file_path, sr=sr)\n",
        "    plot_detection(times, preds)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
